# app.py (Shiny for Python Version)
import pandas as pd
import os
import time
from datetime import datetime

# Shiny æ ¸å¿ƒåº“
from shiny import App, render, ui, reactive
import shinyswatch

# å¯¼å…¥æ‰€æœ‰éœ€è¦çš„æ¨¡å—å’Œå‡½æ•°
from config_utils import Config, logger, BATCH_TRANSLATE_PROMPT, BATCH_AI_SELECT_PROMPT, BATCH_JUDGE_PROMPT, BATCH_ARBITRATE_PROMPT
from step_1_english_match import step_1_initial_english_match
from step_2_translate import step_2_translate_unmatched
from step_3_candidate_matching import step_3_candidate_matching
from step_4_ai_candidate_selection import step_4_ai_candidate_selection
from step_5_ai_judgment import step_5_ai_judgment
from step_6_final_arbitration import step_6_ai_arbitration
from generate_final_report import generate_comprehensive_report

# ==============================================================================
# UI (ç”¨æˆ·ç•Œé¢) å®šä¹‰
# ==============================================================================
app_ui = ui.page_navbar(
    shinyswatch.theme.pulse(), # ä½¿ç”¨ä¸€ä¸ªç°ä»£ä¸»é¢˜
    ui.nav("ğŸ  ä¸»é¡µ & é…ç½®",
        ui.layout_sidebar(
            ui.sidebar(
                ui.h4("âš™ï¸ æ ¸å¿ƒå‚æ•°é…ç½®"),
                ui.input_slider("max_workers", "æœ€å¤§å¹¶å‘æ•°", min=1, max=50, value=Config.MAX_WORKERS),
                ui.input_slider("candidate_limit", "æ¨¡ç³ŠåŒ¹é…å€™é€‰æ•°é‡", min=5, max=50, value=Config.CANDIDATE_LIMIT),
                ui.hr(),
                ui.h4("ğŸ“ æ–‡ä»¶è·¯å¾„é…ç½®"),
                ui.input_text("raw_parquet_file", "åŸå§‹æ•°æ®æ–‡ä»¶è·¯å¾„", value=Config.RAW_PARQUET_FILE),
                ui.input_text("site_dict_file", "æœºæ„å­—å…¸æ–‡ä»¶è·¯å¾„", value=Config.SITE_DICT_FILE),
                ui.input_text("results_dir", "ç»“æœè¾“å‡ºç›®å½•", value=Config.RESULTS_DIR),
            ),
            ui.h2("ğŸ¥ åŒ»ç–—æœºæ„åç§°æ™ºèƒ½åŒ¹é…ä¸æ ‡å‡†åŒ–ç³»ç»Ÿ"),
            ui.markdown("æ¬¢è¿ä½¿ç”¨ï¼è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ é…ç½®æ‚¨çš„APIä¿¡æ¯å’Œæ–‡ä»¶è·¯å¾„ã€‚"),
            ui.hr(),
            ui.h4("ğŸ”‘ API ä¸æ¨¡å‹é…ç½®"),
            ui.input_text("openai_base_url", "OpenAI API Base URL", value=Config.OPENAI_BASE_URL),
            ui.input_password("openai_api_key", "OpenAI API Key", value=""),
            ui.input_text("translate_model", "ç¿»è¯‘æ¨¡å‹", value=Config.TRANSLATE_MODEL),
            ui.hr(),
            ui.input_text("genai_base_url", "Google GenAI Base URL", value=Config.GENAI_BASE_URL),
            ui.input_password("genai_api_key", "Google GenAI API Key", value=""),
            ui.row(
                ui.column(4, ui.input_text("select_model", "é€‰æ‹©æ¨¡å‹", value=Config.AI_SELECT_MODEL)),
                ui.column(4, ui.input_text("judge_model", "åˆ¤æ–­æ¨¡å‹", value=Config.AI_JUDGE_MODEL)),
                ui.column(4, ui.input_text("arbitrate_model", "ä»²è£æ¨¡å‹", value=Config.ARBITRATE_MODEL)),
            )
        )
    ),
    ui.nav("ğŸ“ Prompt ç¼–è¾‘å™¨",
        ui.h2("ğŸ“ Prompt ç¼–è¾‘å™¨"),
        ui.markdown("åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥å®æ—¶æŸ¥çœ‹å’Œä¿®æ”¹ç”¨äºAIå¤„ç†çš„ç³»ç»Ÿæç¤ºè¯ (Prompt)ã€‚"),
        ui.accordion(
            ui.accordion_panel("Step 2: ç¿»è¯‘ Prompt", ui.input_text_area("prompt_translate", "", value=BATCH_TRANSLATE_PROMPT, height="400px")),
            ui.accordion_panel("Step 4: AIé€‰æ‹© Prompt", ui.input_text_area("prompt_select", "", value=BATCH_AI_SELECT_PROMPT, height="400px")),
            ui.accordion_panel("Step 5: AIåˆ¤æ–­ Prompt", ui.input_text_area("prompt_judge", "", value=BATCH_JUDGE_PROMPT, height="400px")),
            ui.accordion_panel("Step 6: AIä»²è£ Prompt", ui.input_text_area("prompt_arbitrate", "", value=BATCH_ARBITRATE_PROMPT, height="400px")),
        )
    ),
    ui.nav("ğŸš€ æ‰§è¡Œ & ç»“æœ",
        ui.h2("ğŸš€ æ‰§è¡Œæµæ°´çº¿ & æŸ¥çœ‹ç»“æœ"),
        ui.input_checkbox_group(
            "steps_to_run",
            "é€‰æ‹©è¦æ‰§è¡Œçš„æ­¥éª¤:",
            {
                "step1": "Step 1: è‹±æ–‡ç²¾ç¡®åŒ¹é…", "step2": "Step 2: AI ç¿»è¯‘",
                "step3": "Step 3: å€™é€‰åŒ¹é…", "step4": "Step 4: AI å€™é€‰é€‰æ‹©",
                "step5": "Step 5: AI åˆ¤æ–­", "step6": "Step 6: AI æœ€ç»ˆä»²è£",
                "step7": "Step 7: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"
            },
            selected=["step1", "step2", "step3", "step4", "step5", "step6", "step7"],
            inline=True
        ),
        ui.input_action_button("run_pipeline", "ğŸš€ æ‰§è¡Œæ‰€é€‰æ­¥éª¤", class_="btn-primary"),
        ui.hr(),
        ui.h4("ğŸ“œ æ‰§è¡Œæ—¥å¿—"),
        ui.output_text_verbatim("run_log"),
        ui.hr(),
        ui.h4("ğŸ“Š æœ€ç»ˆæŠ¥å‘Š"),
        ui.output_ui("report_display")
    ),
    title="åŒ»ç–—æœºæ„åŒ¹é…ç³»ç»Ÿ"
)

# ==============================================================================
# Server (åå°é€»è¾‘) å®šä¹‰
# ==============================================================================
def server(input, output, session):
    
    # --- å“åº”å¼å˜é‡ ---
    # åˆ›å»ºä¸€ä¸ªå“åº”å¼çš„å€¼æ¥å­˜å‚¨æ—¥å¿—
    log_messages = reactive.Value(["### ğŸš€ æµæ°´çº¿æ‰§è¡Œæ—¥å¿—\n\n"])
    
    @reactive.Calc
    def get_dynamic_config():
        """åˆ›å»ºä¸€ä¸ªåŠ¨æ€çš„é…ç½®å¯¹è±¡ï¼Œå®ƒä¼šå“åº”UIä¸Šçš„ä»»ä½•å˜åŒ–"""
        config = Config()
        # ä»UIè¾“å…¥æ›´æ–°é…ç½®
        config.MAX_WORKERS = input.max_workers()
        config.CANDIDATE_LIMIT = input.candidate_limit()
        config.RAW_PARQUET_FILE = input.raw_parquet_file()
        config.SITE_DICT_FILE = input.site_dict_file()
        config.RESULTS_DIR = input.results_dir()
        config.OPENAI_BASE_URL = input.openai_base_url()
        config.OPENAI_API_KEY = input.openai_api_key()
        config.TRANSLATE_MODEL = input.translate_model()
        config.GENAI_BASE_URL = input.genai_base_url()
        config.GENAI_API_KEY = input.genai_api_key()
        config.AI_SELECT_MODEL = input.select_model()
        config.AI_JUDGE_MODEL = input.judge_model()
        config.ARBITRATE_MODEL = input.arbitrate_model()
        
        # æ›´æ–° Prompts
        config.BATCH_TRANSLATE_PROMPT = input.prompt_translate()
        config.BATCH_AI_SELECT_PROMPT = input.prompt_select()
        config.BATCH_JUDGE_PROMPT = input.prompt_judge()
        config.BATCH_ARBITRATE_PROMPT = input.prompt_arbitrate()
        
        return config

    @output
    @render.text
    def run_log():
        """æ¸²æŸ“æ—¥å¿—è¾“å‡ºåŒºåŸŸ"""
        return "".join(log_messages())

    @reactive.Effect
    @reactive.event(input.run_pipeline)
    def _():
        """å½“â€œæ‰§è¡Œâ€æŒ‰é’®è¢«ç‚¹å‡»æ—¶ï¼Œè§¦å‘æ­¤å‡½æ•°"""
        dynamic_config = get_dynamic_config()
        os.makedirs(dynamic_config.RESULTS_DIR, exist_ok=True)
        
        # é‡ç½®æ—¥å¿—
        log_messages.set(["### ğŸš€ æµæ°´çº¿æ‰§è¡Œæ—¥å¿—\n\n"])

        def run_step(step_func, step_name):
            new_log = log_messages()
            new_log.append(f"**{datetime.now().strftime('%H:%M:%S')} - æ­£åœ¨æ‰§è¡Œ {step_name}...**\n")
            log_messages.set(new_log)
            
            success = step_func(dynamic_config) # å‡è®¾å‡½æ•°è¿”å› True/False
            
            new_log = log_messages()
            if success:
                new_log.append(f"**{datetime.now().strftime('%H:%M:%S')} - âœ… {step_name} å®Œæˆï¼**\n\n")
            else:
                new_log.append(f"**{datetime.now().strftime('%H:%M:%S')} - âŒ {step_name} å¤±è´¥ï¼æµæ°´çº¿ç»ˆæ­¢ã€‚**\n\n")
            log_messages.set(new_log)
            return success

        pipeline_steps = {
            "step1": ("Step 1: è‹±æ–‡ç²¾ç¡®åŒ¹é…", step_1_initial_english_match),
            "step2": ("Step 2: AI ç¿»è¯‘", step_2_translate_unmatched),
            "step3": ("Step 3: å€™é€‰åŒ¹é…", step_3_candidate_matching),
            "step4": ("Step 4: AI å€™é€‰é€‰æ‹©", step_4_ai_candidate_selection),
            "step5": ("Step 5: AI åˆ¤æ–­", step_5_ai_judgment),
            "step6": ("Step 6: AI æœ€ç»ˆä»²è£", step_6_ai_arbitration),
            "step7": ("Step 7: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š", generate_comprehensive_report)
        }
        
        # åœ¨ä¸€ä¸ªæ–°çº¿ç¨‹ä¸­è¿è¡Œï¼Œé˜²æ­¢UIè¢«é˜»å¡
        def pipeline_thread():
            for step_key in input.steps_to_run():
                step_name, step_func = pipeline_steps[step_key]
                if not run_step(step_func, step_name):
                    break
        
        thread = Thread(target=pipeline_thread)
        thread.start()

    @output
    @render.ui
    def report_display():
        """æ¸²æŸ“æœ€ç»ˆçš„HTMLæŠ¥å‘Š"""
        # ä¾èµ–äºâ€œæ‰§è¡Œâ€æŒ‰é’®ï¼Œå¹¶ä¸”åœ¨æŠ¥å‘Šæ–‡ä»¶å­˜åœ¨æ—¶è‡ªåŠ¨åˆ·æ–°
        input.run_pipeline() 
        
        report_path = get_dynamic_config().FINAL_REPORT_OUTPUT_FILE
        if os.path.exists(report_path):
            with open(report_path, 'r', encoding='utf-8') as f:
                html_content = f.read()
            return ui.HTML(f'<iframe srcdoc="{html_content.replace("\"", "&quot;")}" width="100%" height="800px" style="border:none;"></iframe>')
        else:
            return ui.p("å°šæœªç”ŸæˆæŠ¥å‘Šã€‚è¯·é€‰æ‹©æ­¥éª¤å¹¶ç‚¹å‡»â€œæ‰§è¡Œâ€ã€‚")

# ==============================================================================
# App å®ä¾‹åŒ–
# ==============================================================================
app = App(app_ui, server)